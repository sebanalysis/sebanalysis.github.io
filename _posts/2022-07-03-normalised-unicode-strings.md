---
layout: post
title: Normalised Unicode Strings
permalink: code/normalised-unicode-strings
categories: code
tags:
---
Due to inconsistent use of combining characters, and alternate ways of  writing the same letter, Unicode developed ways of [normalising characters](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization), for comparison and consistency.

Unicode defines 2 [normalisation vectors](https://youtu.be/_mZBa3sqTrI?t=2081) for Unicode characters. Defined as follows:

1. Composition `â€¦C` (can be done with un-canonsied characters) :
    1. Compose: squash down into smallest number of code points. I.e. , `a` + `U+0300`' `â—ŒÌ€` ('[Combining Grave Accent](https://en.wikipedia.org/wiki/%CC%80)') +  is replaced by `Ã `.
    2. Decompose: stretch out into longest number of code-points, all the accents get spun out into combining characters, i.e. `Ã ` is replaced by  `a` + `â—ŒÌ€`.

2. Canon `â€¦D` (always done in conjunction with either a full composed or fully decomposed string):
    1. Canonise `â€¦Kâ€¦`: Convert the code-point into the "canonical version" of the character. I.e. `Â²` becomes `2`.
    2. Leave un-canonised `â€¦`:  Leave the character as-is

The french Wikipedia page, has [a better diagram](https://fr.wikipedia.org/wiki/Normalisation_Unicode) to show what "Composition" and "Canon" do.

These two methods provide a matrix of 4 possible normalised forms of unicode strings, with the crypic names "NFC", "NFD", "NFKC", "NFKD":

 Normalised Forms |Composed | Decomposed
-|-|-
__Non-Canonical__ | `NFC` | `NFD`
__Canonical__ | `NFKC` | `NFKD`

The function `unicodedata.normalize( "form", "string" )` takes one of these four normalisation forms as an arguement and returns a normalised string.

***

## Examples

Lets compare some characters after applying the 4 different normalisation methods. Are the strings equal?

First import the `unicodedata` module from the standard library:

```python
import unicodedata as uc
```

The 4 normalised-forms:

```python
NF = ["NFC", "NFD", "NFKC", "NFKD"]
```

Using the comparison `a == A` as an example.

```python
>>>for x in NF: x ,uc.normalize( x  ,  "a") == uc.normalize( x  ,  "A")
...
('NFC', False)
('NFD', False)
('NFKC', False)
('NFKD', False)
```

***

### Different Capitalisation `a == A`

Unnormalised, `a â‰  A`

Shown more clearly with both characters normalised in the same way:

 __`a == A`__ |Composed | Decomposed
-|-|-
__Non-Canonical__ | `NFC`âŒ | `NFD`âŒ
__Canonical__ | `NFKC` âŒ | `NFKD` âŒ

The `.normalize` method, has no effect on case. Have to use the`.lower()` method on both strings to do a case insensitive comparison.

***

### Different Form of Same "Canonical" Character:   __`â‘  == 1`__

Unnormalised, `â‘  â‰  1`

With both characters normalised in the same way and ignoring the code:

 __`â‘  == 1`__ |Composed | Decomposed
-|-|-
__Non-Canonical__ | `NFC`âŒ | `NFD`âŒ
__Canonical__ | `NFKC` âœ… | `NFKD` âœ…

`â‘ `and`1` are the same 'canonical' character despite being different code-points.

***

### Different Form of Same "Canonical" Character:    __`y == ğ’š`__

Unnormalised, `y â‰  ğ’š`

With both characters normalised in the same way:

__`y == ğ’š`__ |Composed | Decomposed
-|-|-
__Non-Canonical__ | `NFC`âŒ | `NFD`âŒ
__Canonical__ | `NFKC` âœ… | `NFKD` âœ…

`y`and`ğ’š` are the same 'canonical' character  despite being different code-points.

However, for information: __`ÃŸ â‰  SS`__ and __`a â‰  Î±`__.

***

### Composed vs Decomposed Letter:  `Ã   == â—ŒÌ€ + a`

Unnormalised, `Ã   â‰  â—ŒÌ€ + a`

with both characters normalised in the same way:

__`Ã   == â—ŒÌ€ + a`__ |Composed | Decomposed
-|-|-
__Non-Canonical__ | `NFC`âœ… | `NFD`âœ…
__Canonical__ | `NFKC` âœ…| `NFKD` âœ…

In composed form, `a + â—ŒÌ€`  becomes `Ã `.  When decomposed, `Ã ` becomes `a + â—ŒÌ€`. So they are always the same characters.

### Resources

Talk: [Dylan Beattie Talk on Plain text NDC Oslo](https://youtu.be/_mZBa3sqTrI?t=2066)
