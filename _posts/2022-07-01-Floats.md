---
layout: post
title: Floats
permalink: Floats
date: 2022-07-01
category: 
tags: 
---
# Floats

"Floats" or "Floating Point Numbers", are approximations of decimal numbers, using binary notation.

In mathematics, we commonly write long or short decimal numbers in the form: 

## $$Â±x Ã— 10^{Â±y}$$

But in all computers, this is automatically converted into in binary. Specifically, it is stored in the form:

## $$Â±x Ã— 2^{Â±y}$$

Where:
ğ’™ : The __Mantissa__ (a.k.a. "significand") is limited to 52 bits.
ğ’š : The __Exponent__ is limited to 11 bits.

It is stored in the the following format called "IEEE_745" a.k.a. "float64" or "double-precision" (as it is double the length of the 32 bit representations used on older computers).

![](https://filedn.eu/ldJhAY64zF58aVds1pK8ovH/IEEE_754_Double_Floating_Point_Forma.svg)

<div align="center">Float Representation in memory in "float64"</div>


__Note__ there is a further complication:
- The __Exponent__  is encoded using the "offset-binary" scheme. In  "offset-binary", the sign is implicit, and does not require an extra bit to be expressed.
- The __Mantissa__ is encoded literally, hence the need for the sign at the beginning of the expression.

"float64" provides __between 15__ and __17 significant decimal digits__ of precision and is the standard used in python.

The limitations of this float representation are :
- When checking equality between seemingly equivalent values and finding `False`
- When more that 15 significant decimal digits are needed.

### Resources
[Tom Scott](https://www.youtube.com/watch?v=PZRI1IfStY0)
